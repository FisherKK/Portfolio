{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T16:18:45.168045Z",
     "start_time": "2019-11-24T16:18:45.113080Z"
    }
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors is an Supervised Learning algorithm usually used for classification. It stores all available cases and provides classification for new ones based on it's similarity to stored cases. \n",
    "\n",
    "### Setup\n",
    "---\n",
    "Given a vector $c$ of $l$ **classes** (categories, describing some sample e.g. flower species, itemp type):\n",
    "\n",
    "$$\n",
    "c = [c_{0}, c_{1}, c_{2}, \\dots, c_{l}]\n",
    "$$\n",
    "\n",
    "---\n",
    "Given a group of representative samples, stored inside matrix $X_{rep}$ of size $m \\times n$, and given a vector $y_{rep}$ of size $m$, storing one classes from vector $c$ for each sample of matrix $X_{rep}$:\n",
    "\n",
    "$$\n",
    "X_{rep} = \n",
    "\\begin{bmatrix}\n",
    "x_{00} & x_{01} & x_{02} & \\dots & x_{0n} \\\\\n",
    "x_{10} & x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "x_{20} & x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m0} & x_{m1} & x_{m2} & \\dots & x_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    ",\n",
    "y_{rep} = \n",
    "\\begin{bmatrix}\n",
    "y_{0} \\\\\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{m} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ m $ - number of samples\n",
    "- $ n $ - number of features\n",
    "\n",
    "--- \n",
    "Given a group of samples stored in matrix $X_{new}$ of size $o \\times n$, which are different than those stored inside $X_{rep}$ matrix:\n",
    "\n",
    "$$\n",
    "X_{new} = \n",
    "\\begin{bmatrix}\n",
    "x_{00} & x_{01} & x_{02} & \\dots & x_{0n} \\\\\n",
    "x_{10} & x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "x_{20} & x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m0} & x_{m1} & x_{m2} & \\dots & x_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Goal\n",
    "\n",
    "The goal is to assign one of classes from vector $c$ for each one of $o$ samples stored inside matrix $X_{new}$ with usage of `KNN` algorithm.\n",
    "\n",
    "### Algorithm\n",
    "For given sample $x_{i}$ ($i\\in{o}$) of matrix $X_{new}$, `KNN` calculates **distance** between every sample $x_{j}$ ($j\\in{m}$) from matrix $X_{rep}$ and given sample $x_{i}$. The distances are sorted and group of $k$ **neighbors** (samples from matrix $X_{rep}$ which distance is closest to sample $x_{i}$) is selected. Class assigned to sample $x_{i}$ is the most appearing class inside selected group of $k$ neighbors (this process is called **vote**). To avoid draw during vote process, value of $k$ parameter should be odd. \n",
    "\n",
    "### Distance\n",
    "The `KNN` can use various distance metrics for comparing vectors representing samples. Most common distances are `Euclidean Distance` and `Manhattan Distance`:\n",
    "\n",
    "#### 1. Euclidean Distance\n",
    "\n",
    "$$d(p,q) = \\sum_{i=1}^{n}\\sqrt{(p_{i} - q_{i})^2}$$\n",
    "\n",
    "where:\n",
    "- $p$ - vector\n",
    "- $q$ - vector\n",
    "- $n$ - number of elements\n",
    "\n",
    "#### 2. Manhattan Distance\n",
    "\n",
    "$$d(p,q) = \\sum_{i=1}^{n}|p_{i} - q_{i}|$$\n",
    "\n",
    "where:\n",
    "- $p$ - vector\n",
    "- $q$ - vector\n",
    "- $n$ - number of elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:05:45.454826Z",
     "start_time": "2019-11-24T20:05:45.451540Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:05:45.460377Z",
     "start_time": "2019-11-24T20:05:45.456765Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Function loads dictionary containing iris dataset from scikit-learn\n",
    "    library and splits samples in stratified way, in 0.8/0.2 ratio, into \n",
    "    train and test datasets.\n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "    samples, targets = iris[\"data\"], iris[\"target\"]\n",
    "    return train_test_split(\n",
    "        samples, targets, \n",
    "        test_size=0.2, \n",
    "        stratify=targets,\n",
    "        shuffle=True, \n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:05:45.466146Z",
     "start_time": "2019-11-24T20:05:45.462325Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(P, Q):\n",
    "    \"\"\"Function returning row-wise Euclidean Distance values for \n",
    "    matrices P and Q. Works with just vectors.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(P - Q, axis=1)\n",
    "\n",
    "def manhattan_distance(P, Q):\n",
    "    \"\"\"Function returning row-wise Manhattan Distance values for \n",
    "    matrices P and Q. Works with just vectors.\n",
    "    \"\"\"\n",
    "    return np.abs(P - Q).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:05:45.474100Z",
     "start_time": "2019-11-24T20:05:45.468180Z"
    }
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"K Nearest Neighbor algorithm implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, k, distance):\n",
    "        \"\"\"Constructor of KNN function.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k: int\n",
    "            Number of neighbors that will be used in class vote.\n",
    "        distance: function\n",
    "            Function for calculating distance between samples.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "        \n",
    "    def _predict_for_sample(self, sample, X_rep, y_rep):\n",
    "        \"\"\"Implementation of KNN for single sample:\n",
    "        1. Calculates distance betwen sample and all rows of X_rep.\n",
    "        2. Sorts calculated distances and picks ids of rows which distance \n",
    "           is closest to sample.\n",
    "        3. Selects subset of k labels from vector y_rep based on previously\n",
    "           picked indices.\n",
    "        4. Returns most appearing class.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sample: numpy.ndarray\n",
    "            Vector containing feature values of single sample.\n",
    "        X_rep: numpy.ndarray\n",
    "            Matrix of samples based on which predictions will be made.\n",
    "        y_rep: numpy.ndarray\n",
    "            Vector containing class ids for each row in matrix X_rep.\n",
    "            \n",
    "        Returns:\n",
    "        -----------\n",
    "        result: int\n",
    "            Returns class id of most similar class to given sample.\n",
    "        \"\"\"\n",
    "        distances = self.distance(X_rep, sample)\n",
    "        k_neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "        return np.bincount(y_rep[k_neighbors]).argmax()\n",
    "        \n",
    "    def predict(self, X_new, X_rep, y_rep):\n",
    "        \"\"\"Function that for each row of matrix X_new performs classification \n",
    "        based on matrix X_rep and it's labels y_rep.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_new: numpy.ndarray\n",
    "            Matrix of samples for which predictions will be made.\n",
    "        X_rep: numpy.ndarray\n",
    "            Matrix of samples based on which predictions will be made.\n",
    "        y_rep: numpy.ndarray\n",
    "            Vector containing class ids for each row in matrix X_rep.\n",
    "            \n",
    "        Returns:\n",
    "        -----------\n",
    "        result: numpy.ndarray\n",
    "            Vector containing predicted class ids for each row in \n",
    "            matrix X_new.\n",
    "        \"\"\"\n",
    "        return np.array([self._predict_for_sample(s, X_rep, y_rep) for s in X_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:36:34.649289Z",
     "start_time": "2019-11-24T20:36:34.637080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_rep matrix size: (120, 4)\n",
      "y_rep vector size: (120,)\n",
      "X_new matrix size: (30, 4)\n",
      "y_new vector size: (30,)\n",
      "\n",
      "----\n",
      "\n",
      "Prediction vector: [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 1 1 0 2 0]\n",
      "  Expected values: [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 1 1 0 2 0]\n",
      "\n",
      "----\n",
      "\n",
      "Prediction accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "X_rep, X_new, y_rep, y_new = load_data()\n",
    "print(\"X_rep matrix size: {}\".format(X_rep.shape))\n",
    "print(\"y_rep vector size: {}\".format(y_rep.shape))\n",
    "print(\"X_new matrix size: {}\".format(X_new.shape))\n",
    "print(\"y_new vector size: {}\".format(y_new.shape))\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Creating KNN object\n",
    "knn = KNN(k=5, distance=euclidean_distance)\n",
    "\n",
    "# Making prediction\n",
    "pred = knn.predict(X_new, X_rep, y_rep)\n",
    "print(\"Prediction vector: {}\".format(pred))\n",
    "print(\"  Expected values: {}\".format(y_new))\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(pred, y_new)\n",
    "print(\"Prediction accuracy: {}%\".format(accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
